<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.1" />
<title>8_pytorch_rfbnet.lib.infer_detector API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>8_pytorch_rfbnet.lib.infer_detector</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import sys
import os
import pickle
import argparse
import cv2
import torch
import torch.nn as nn
import torch.backends.cudnn as cudnn
import torchvision.transforms as transforms
import numpy as np
from torch.autograd import Variable
from data import VOCroot,COCOroot 
from data import AnnotationTransform, COCODetection, VOCDetection, BaseTransform, VOC_300,VOC_512,COCO_300,COCO_512, COCO_mobile_300

import torch.utils.data as data
&#39;&#39;&#39;
from layers.functions import Detect,PriorBox
from utils.nms_wrapper import nms
from utils.timer import Timer
&#39;&#39;&#39;

class Infer():
    &#39;&#39;&#39;
    Class for main inference

    Args:
        verbose (int): Set verbosity levels
                        0 - Print Nothing
                        1 - Print desired details
    &#39;&#39;&#39;
    def __init__(self, verbose=1):
        self.system_dict = {};
        self.system_dict[&#34;verbose&#34;] = verbose;
        self.system_dict[&#34;local&#34;] = {};
        self.system_dict[&#34;params&#34;] = {};

        self.system_dict[&#34;params&#34;][&#34;dataset&#34;] = &#34;COCO&#34;;
        self.system_dict[&#34;params&#34;][&#34;version&#34;] = &#34;RFB_vgg&#34;;
        self.system_dict[&#34;params&#34;][&#34;size&#34;] = 512;
        self.system_dict[&#34;params&#34;][&#34;cuda&#34;] = True;
        self.system_dict[&#34;params&#34;][&#34;cpu&#34;] = False;
        self.system_dict[&#34;params&#34;][&#34;retest&#34;] = False;

        self.system_dict[&#34;params&#34;][&#34;trained_model&#34;] = &#34;&#34;;
        self.system_dict[&#34;params&#34;][&#34;save_folder&#34;] = &#34;eval&#34;;

        self.system_dict[&#34;local&#34;][&#34;img_file&#34;] = &#34;&#34;;
        self.system_dict[&#34;local&#34;][&#34;thresh&#34;] = 0.3;
        self.system_dict[&#34;local&#34;][&#34;classes&#34;] = [&#34;__bg__&#34;];


    def Model(self, model_name=&#34;vgg&#34;, weights=&#34;weights/Final_RFB_vgg_COCO.pth&#34;, use_gpu=True):
        &#39;&#39;&#39;
        User function: Selet trained model params

        Args:
            model_name (str): Select the right model
            weights (str): Relative path to the trained model 
            use_gpu (bool): If True, model is loaded on GPU else cpu

        Returns:
            None
        &#39;&#39;&#39;
        if(model_name == &#34;vgg&#34;):
            self.system_dict[&#34;params&#34;][&#34;version&#34;] = &#34;RFB_vgg&#34;;
        elif(model_name == &#34;e_vgg&#34;):
            self.system_dict[&#34;params&#34;][&#34;version&#34;] = &#34;RFB_E_vgg&#34;;
        elif(model_name == &#34;mobilenet&#34;):
            self.system_dict[&#34;params&#34;][&#34;version&#34;] = &#34;RFB_mobile&#34;;

        self.system_dict[&#34;params&#34;][&#34;trained_model&#34;] = weights;        

        if(use_gpu):
            self.system_dict[&#34;params&#34;][&#34;cuda&#34;] = True;
            self.system_dict[&#34;params&#34;][&#34;cpu&#34;] = False;
        else:
            self.system_dict[&#34;params&#34;][&#34;cuda&#34;] = False;
            self.system_dict[&#34;params&#34;][&#34;cpu&#34;] = True;


    def Image_Params(self, class_file, input_size=512):
        &#39;&#39;&#39;
        User function: Set trained model params

        Args:
            class_file (str): Path to file containing class names
            input_size (int): Input image shape

        Returns:
            None
        &#39;&#39;&#39;
        self.system_dict[&#34;params&#34;][&#34;size&#34;] = input_size;
        f = open(class_file, &#39;r&#39;);
        lines = f.readlines();
        f.close();
        for i in range(len(lines)):
            self.system_dict[&#34;local&#34;][&#34;classes&#34;].append(lines[i][:len(lines[i])-1])


    def Setup(self):
        &#39;&#39;&#39;
        User function: Setup all parameters

        Args:
            None

        Returns:
            None
        &#39;&#39;&#39;
        if(self.system_dict[&#34;params&#34;][&#34;size&#34;] == 300):
            self.system_dict[&#34;local&#34;][&#34;cfg&#34;] = COCO_300;
        else:
            self.system_dict[&#34;local&#34;][&#34;cfg&#34;] = COCO_512;


        if self.system_dict[&#34;params&#34;][&#34;version&#34;] == &#39;RFB_vgg&#39;:
            from models.RFB_Net_vgg import build_net
        elif self.system_dict[&#34;params&#34;][&#34;version&#34;] == &#39;RFB_E_vgg&#39;:
            from models.RFB_Net_E_vgg import build_net
        elif self.system_dict[&#34;params&#34;][&#34;version&#34;] == &#39;RFB_mobile&#39;:
            from models.RFB_Net_mobile import build_net
            self.system_dict[&#34;local&#34;][&#34;cfg&#34;] = COCO_mobile_300
        else:
            print(&#39;Unkown version!&#39;)


        self.system_dict[&#34;local&#34;][&#34;priorbox&#34;] = PriorBox(self.system_dict[&#34;local&#34;][&#34;cfg&#34;])
        with torch.no_grad():
            self.system_dict[&#34;local&#34;][&#34;priors&#34;] = self.system_dict[&#34;local&#34;][&#34;priorbox&#34;].forward()
            if self.system_dict[&#34;params&#34;][&#34;cuda&#34;]:
                self.system_dict[&#34;local&#34;][&#34;priors&#34;] = self.system_dict[&#34;local&#34;][&#34;priors&#34;].cuda()


        img_dim = (300,512)[self.system_dict[&#34;params&#34;][&#34;size&#34;] == 512]
        num_classes = len(self.system_dict[&#34;local&#34;][&#34;classes&#34;])
        self.system_dict[&#34;local&#34;][&#34;net&#34;] = build_net(&#39;test&#39;, img_dim, num_classes)
        state_dict = torch.load(self.system_dict[&#34;params&#34;][&#34;trained_model&#34;])


        from collections import OrderedDict
        new_state_dict = OrderedDict()
        for k, v in state_dict.items():
            head = k[:7]
            if head == &#39;module.&#39;:
                name = k[7:] # remove `module.`
            else:
                name = k
            new_state_dict[name] = v
        self.system_dict[&#34;local&#34;][&#34;net&#34;].load_state_dict(new_state_dict)
        self.system_dict[&#34;local&#34;][&#34;net&#34;].eval()
        print(&#39;Finished loading model!&#39;)

        if self.system_dict[&#34;params&#34;][&#34;cuda&#34;]:
            self.system_dict[&#34;local&#34;][&#34;net&#34;] = self.system_dict[&#34;local&#34;][&#34;net&#34;].cuda()
            cudnn.benchmark = True
        else:
            self.system_dict[&#34;local&#34;][&#34;net&#34;] = self.system_dict[&#34;local&#34;][&#34;net&#34;].cpu()

        
        self.system_dict[&#34;local&#34;][&#34;detector&#34;] = Detect(num_classes, 0, self.system_dict[&#34;local&#34;][&#34;cfg&#34;])



    
    def Predict(self, img_file, thresh=0.7, font_size=1, line_size=5):
        &#39;&#39;&#39;
        User function: Run inference on image and visualize it

        Args:
            img_file (str): Relative path to the image file
            thresh (float): Threshold for predicted scores. Scores for objects detected below this score will not be displayed 
            font_size (int): Font size for text of label names on predicted images
            line_size (int): Drawn bounding boxes line widths

        Returns:
            list: List of bounding box locations of predicted objects. 
        &#39;&#39;&#39;
        top_k = 200
        img_dim = (300,512)[self.system_dict[&#34;params&#34;][&#34;size&#34;] == 512]
        num_classes = len(self.system_dict[&#34;local&#34;][&#34;classes&#34;])

        rgb_means = ((104, 117, 123),(103.94,116.78,123.68))[self.system_dict[&#34;params&#34;][&#34;version&#34;] == &#39;RFB_mobile&#39;]

        cuda = self.system_dict[&#34;params&#34;][&#34;cuda&#34;];
        transform = BaseTransform(self.system_dict[&#34;local&#34;][&#34;net&#34;].size, rgb_means, (2, 0, 1))
        max_per_image = top_k
        
        num_images = 1
        all_boxes = [];

        _t = {&#39;im_detect&#39;: Timer(), &#39;misc&#39;: Timer()}
        det_file = os.path.join(&#39;detections.pkl&#39;)

        
        img_id = img_file;
        img = cv2.imread(img_id, cv2.IMREAD_COLOR)
        img2 = cv2.imread(img_id, cv2.IMREAD_COLOR)

        scale = torch.Tensor([img.shape[1], img.shape[0],
                     img.shape[1], img.shape[0]])
        with torch.no_grad():
            x = transform(img).unsqueeze(0)
            if cuda:
                x = x.cuda()
                scale = scale.cuda()

        _t[&#39;im_detect&#39;].tic()
        out = self.system_dict[&#34;local&#34;][&#34;net&#34;](x)      # forward pass
        boxes, scores = self.system_dict[&#34;local&#34;][&#34;detector&#34;].forward(out, self.system_dict[&#34;local&#34;][&#34;priors&#34;])
        detect_time = _t[&#39;im_detect&#39;].toc()
        boxes = boxes[0]
        scores=scores[0]

        boxes *= scale
        boxes = boxes.cpu().numpy()
        scores = scores.cpu().numpy()
        # scale each detection back up to the image

        _t[&#39;misc&#39;].tic()

        classes = self.system_dict[&#34;local&#34;][&#34;classes&#34;];

        for j in range(1, num_classes):
            inds = np.where(scores[:, j] &gt; thresh)[0]
            if len(inds) == 0:
                continue
            c_bboxes = boxes[inds]
            c_scores = scores[inds, j]
            c_dets = np.hstack((c_bboxes, c_scores[:, np.newaxis])).astype(
                np.float32, copy=False)

            keep = nms(c_dets, 0.45, force_cpu=self.system_dict[&#34;params&#34;][&#34;cpu&#34;])
            c_dets = c_dets[keep, :]
            c_bboxes=c_dets[:, :4]
            print(len(c_bboxes), j)
            for bbox in c_bboxes:
                cv2.rectangle(img2, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (0, 0, 255), line_size)
                cv2.putText(img2, classes[j], (int(bbox[0]), int(bbox[1])) , 
                            cv2.FONT_HERSHEY_SIMPLEX, font_size, (0, 0, 255), line_size-2)
                all_boxes.append([int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3]), classes[j]])
            
        cv2.imwrite(&#34;output.png&#34;, img2)

        return all_boxes;</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="8_pytorch_rfbnet.lib.infer_detector.Infer"><code class="flex name class">
<span>class <span class="ident">Infer</span></span>
<span>(</span><span>verbose=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Class for main inference</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>verbose</code></strong> :&ensp;<code>int</code></dt>
<dd>Set verbosity levels
0 - Print Nothing
1 - Print desired details</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Infer():
    &#39;&#39;&#39;
    Class for main inference

    Args:
        verbose (int): Set verbosity levels
                        0 - Print Nothing
                        1 - Print desired details
    &#39;&#39;&#39;
    def __init__(self, verbose=1):
        self.system_dict = {};
        self.system_dict[&#34;verbose&#34;] = verbose;
        self.system_dict[&#34;local&#34;] = {};
        self.system_dict[&#34;params&#34;] = {};

        self.system_dict[&#34;params&#34;][&#34;dataset&#34;] = &#34;COCO&#34;;
        self.system_dict[&#34;params&#34;][&#34;version&#34;] = &#34;RFB_vgg&#34;;
        self.system_dict[&#34;params&#34;][&#34;size&#34;] = 512;
        self.system_dict[&#34;params&#34;][&#34;cuda&#34;] = True;
        self.system_dict[&#34;params&#34;][&#34;cpu&#34;] = False;
        self.system_dict[&#34;params&#34;][&#34;retest&#34;] = False;

        self.system_dict[&#34;params&#34;][&#34;trained_model&#34;] = &#34;&#34;;
        self.system_dict[&#34;params&#34;][&#34;save_folder&#34;] = &#34;eval&#34;;

        self.system_dict[&#34;local&#34;][&#34;img_file&#34;] = &#34;&#34;;
        self.system_dict[&#34;local&#34;][&#34;thresh&#34;] = 0.3;
        self.system_dict[&#34;local&#34;][&#34;classes&#34;] = [&#34;__bg__&#34;];


    def Model(self, model_name=&#34;vgg&#34;, weights=&#34;weights/Final_RFB_vgg_COCO.pth&#34;, use_gpu=True):
        &#39;&#39;&#39;
        User function: Selet trained model params

        Args:
            model_name (str): Select the right model
            weights (str): Relative path to the trained model 
            use_gpu (bool): If True, model is loaded on GPU else cpu

        Returns:
            None
        &#39;&#39;&#39;
        if(model_name == &#34;vgg&#34;):
            self.system_dict[&#34;params&#34;][&#34;version&#34;] = &#34;RFB_vgg&#34;;
        elif(model_name == &#34;e_vgg&#34;):
            self.system_dict[&#34;params&#34;][&#34;version&#34;] = &#34;RFB_E_vgg&#34;;
        elif(model_name == &#34;mobilenet&#34;):
            self.system_dict[&#34;params&#34;][&#34;version&#34;] = &#34;RFB_mobile&#34;;

        self.system_dict[&#34;params&#34;][&#34;trained_model&#34;] = weights;        

        if(use_gpu):
            self.system_dict[&#34;params&#34;][&#34;cuda&#34;] = True;
            self.system_dict[&#34;params&#34;][&#34;cpu&#34;] = False;
        else:
            self.system_dict[&#34;params&#34;][&#34;cuda&#34;] = False;
            self.system_dict[&#34;params&#34;][&#34;cpu&#34;] = True;


    def Image_Params(self, class_file, input_size=512):
        &#39;&#39;&#39;
        User function: Set trained model params

        Args:
            class_file (str): Path to file containing class names
            input_size (int): Input image shape

        Returns:
            None
        &#39;&#39;&#39;
        self.system_dict[&#34;params&#34;][&#34;size&#34;] = input_size;
        f = open(class_file, &#39;r&#39;);
        lines = f.readlines();
        f.close();
        for i in range(len(lines)):
            self.system_dict[&#34;local&#34;][&#34;classes&#34;].append(lines[i][:len(lines[i])-1])


    def Setup(self):
        &#39;&#39;&#39;
        User function: Setup all parameters

        Args:
            None

        Returns:
            None
        &#39;&#39;&#39;
        if(self.system_dict[&#34;params&#34;][&#34;size&#34;] == 300):
            self.system_dict[&#34;local&#34;][&#34;cfg&#34;] = COCO_300;
        else:
            self.system_dict[&#34;local&#34;][&#34;cfg&#34;] = COCO_512;


        if self.system_dict[&#34;params&#34;][&#34;version&#34;] == &#39;RFB_vgg&#39;:
            from models.RFB_Net_vgg import build_net
        elif self.system_dict[&#34;params&#34;][&#34;version&#34;] == &#39;RFB_E_vgg&#39;:
            from models.RFB_Net_E_vgg import build_net
        elif self.system_dict[&#34;params&#34;][&#34;version&#34;] == &#39;RFB_mobile&#39;:
            from models.RFB_Net_mobile import build_net
            self.system_dict[&#34;local&#34;][&#34;cfg&#34;] = COCO_mobile_300
        else:
            print(&#39;Unkown version!&#39;)


        self.system_dict[&#34;local&#34;][&#34;priorbox&#34;] = PriorBox(self.system_dict[&#34;local&#34;][&#34;cfg&#34;])
        with torch.no_grad():
            self.system_dict[&#34;local&#34;][&#34;priors&#34;] = self.system_dict[&#34;local&#34;][&#34;priorbox&#34;].forward()
            if self.system_dict[&#34;params&#34;][&#34;cuda&#34;]:
                self.system_dict[&#34;local&#34;][&#34;priors&#34;] = self.system_dict[&#34;local&#34;][&#34;priors&#34;].cuda()


        img_dim = (300,512)[self.system_dict[&#34;params&#34;][&#34;size&#34;] == 512]
        num_classes = len(self.system_dict[&#34;local&#34;][&#34;classes&#34;])
        self.system_dict[&#34;local&#34;][&#34;net&#34;] = build_net(&#39;test&#39;, img_dim, num_classes)
        state_dict = torch.load(self.system_dict[&#34;params&#34;][&#34;trained_model&#34;])


        from collections import OrderedDict
        new_state_dict = OrderedDict()
        for k, v in state_dict.items():
            head = k[:7]
            if head == &#39;module.&#39;:
                name = k[7:] # remove `module.`
            else:
                name = k
            new_state_dict[name] = v
        self.system_dict[&#34;local&#34;][&#34;net&#34;].load_state_dict(new_state_dict)
        self.system_dict[&#34;local&#34;][&#34;net&#34;].eval()
        print(&#39;Finished loading model!&#39;)

        if self.system_dict[&#34;params&#34;][&#34;cuda&#34;]:
            self.system_dict[&#34;local&#34;][&#34;net&#34;] = self.system_dict[&#34;local&#34;][&#34;net&#34;].cuda()
            cudnn.benchmark = True
        else:
            self.system_dict[&#34;local&#34;][&#34;net&#34;] = self.system_dict[&#34;local&#34;][&#34;net&#34;].cpu()

        
        self.system_dict[&#34;local&#34;][&#34;detector&#34;] = Detect(num_classes, 0, self.system_dict[&#34;local&#34;][&#34;cfg&#34;])



    
    def Predict(self, img_file, thresh=0.7, font_size=1, line_size=5):
        &#39;&#39;&#39;
        User function: Run inference on image and visualize it

        Args:
            img_file (str): Relative path to the image file
            thresh (float): Threshold for predicted scores. Scores for objects detected below this score will not be displayed 
            font_size (int): Font size for text of label names on predicted images
            line_size (int): Drawn bounding boxes line widths

        Returns:
            list: List of bounding box locations of predicted objects. 
        &#39;&#39;&#39;
        top_k = 200
        img_dim = (300,512)[self.system_dict[&#34;params&#34;][&#34;size&#34;] == 512]
        num_classes = len(self.system_dict[&#34;local&#34;][&#34;classes&#34;])

        rgb_means = ((104, 117, 123),(103.94,116.78,123.68))[self.system_dict[&#34;params&#34;][&#34;version&#34;] == &#39;RFB_mobile&#39;]

        cuda = self.system_dict[&#34;params&#34;][&#34;cuda&#34;];
        transform = BaseTransform(self.system_dict[&#34;local&#34;][&#34;net&#34;].size, rgb_means, (2, 0, 1))
        max_per_image = top_k
        
        num_images = 1
        all_boxes = [];

        _t = {&#39;im_detect&#39;: Timer(), &#39;misc&#39;: Timer()}
        det_file = os.path.join(&#39;detections.pkl&#39;)

        
        img_id = img_file;
        img = cv2.imread(img_id, cv2.IMREAD_COLOR)
        img2 = cv2.imread(img_id, cv2.IMREAD_COLOR)

        scale = torch.Tensor([img.shape[1], img.shape[0],
                     img.shape[1], img.shape[0]])
        with torch.no_grad():
            x = transform(img).unsqueeze(0)
            if cuda:
                x = x.cuda()
                scale = scale.cuda()

        _t[&#39;im_detect&#39;].tic()
        out = self.system_dict[&#34;local&#34;][&#34;net&#34;](x)      # forward pass
        boxes, scores = self.system_dict[&#34;local&#34;][&#34;detector&#34;].forward(out, self.system_dict[&#34;local&#34;][&#34;priors&#34;])
        detect_time = _t[&#39;im_detect&#39;].toc()
        boxes = boxes[0]
        scores=scores[0]

        boxes *= scale
        boxes = boxes.cpu().numpy()
        scores = scores.cpu().numpy()
        # scale each detection back up to the image

        _t[&#39;misc&#39;].tic()

        classes = self.system_dict[&#34;local&#34;][&#34;classes&#34;];

        for j in range(1, num_classes):
            inds = np.where(scores[:, j] &gt; thresh)[0]
            if len(inds) == 0:
                continue
            c_bboxes = boxes[inds]
            c_scores = scores[inds, j]
            c_dets = np.hstack((c_bboxes, c_scores[:, np.newaxis])).astype(
                np.float32, copy=False)

            keep = nms(c_dets, 0.45, force_cpu=self.system_dict[&#34;params&#34;][&#34;cpu&#34;])
            c_dets = c_dets[keep, :]
            c_bboxes=c_dets[:, :4]
            print(len(c_bboxes), j)
            for bbox in c_bboxes:
                cv2.rectangle(img2, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (0, 0, 255), line_size)
                cv2.putText(img2, classes[j], (int(bbox[0]), int(bbox[1])) , 
                            cv2.FONT_HERSHEY_SIMPLEX, font_size, (0, 0, 255), line_size-2)
                all_boxes.append([int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3]), classes[j]])
            
        cv2.imwrite(&#34;output.png&#34;, img2)

        return all_boxes;</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="8_pytorch_rfbnet.lib.infer_detector.Infer.Image_Params"><code class="name flex">
<span>def <span class="ident">Image_Params</span></span>(<span>self, class_file, input_size=512)</span>
</code></dt>
<dd>
<div class="desc"><p>User function: Set trained model params</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>class_file</code></strong> :&ensp;<code>str</code></dt>
<dd>Path to file containing class names</dd>
<dt><strong><code>input_size</code></strong> :&ensp;<code>int</code></dt>
<dd>Input image shape</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def Image_Params(self, class_file, input_size=512):
    &#39;&#39;&#39;
    User function: Set trained model params

    Args:
        class_file (str): Path to file containing class names
        input_size (int): Input image shape

    Returns:
        None
    &#39;&#39;&#39;
    self.system_dict[&#34;params&#34;][&#34;size&#34;] = input_size;
    f = open(class_file, &#39;r&#39;);
    lines = f.readlines();
    f.close();
    for i in range(len(lines)):
        self.system_dict[&#34;local&#34;][&#34;classes&#34;].append(lines[i][:len(lines[i])-1])</code></pre>
</details>
</dd>
<dt id="8_pytorch_rfbnet.lib.infer_detector.Infer.Model"><code class="name flex">
<span>def <span class="ident">Model</span></span>(<span>self, model_name='vgg', weights='weights/Final_RFB_vgg_COCO.pth', use_gpu=True)</span>
</code></dt>
<dd>
<div class="desc"><p>User function: Selet trained model params</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>model_name</code></strong> :&ensp;<code>str</code></dt>
<dd>Select the right model</dd>
<dt><strong><code>weights</code></strong> :&ensp;<code>str</code></dt>
<dd>Relative path to the trained model </dd>
<dt><strong><code>use_gpu</code></strong> :&ensp;<code>bool</code></dt>
<dd>If True, model is loaded on GPU else cpu</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def Model(self, model_name=&#34;vgg&#34;, weights=&#34;weights/Final_RFB_vgg_COCO.pth&#34;, use_gpu=True):
    &#39;&#39;&#39;
    User function: Selet trained model params

    Args:
        model_name (str): Select the right model
        weights (str): Relative path to the trained model 
        use_gpu (bool): If True, model is loaded on GPU else cpu

    Returns:
        None
    &#39;&#39;&#39;
    if(model_name == &#34;vgg&#34;):
        self.system_dict[&#34;params&#34;][&#34;version&#34;] = &#34;RFB_vgg&#34;;
    elif(model_name == &#34;e_vgg&#34;):
        self.system_dict[&#34;params&#34;][&#34;version&#34;] = &#34;RFB_E_vgg&#34;;
    elif(model_name == &#34;mobilenet&#34;):
        self.system_dict[&#34;params&#34;][&#34;version&#34;] = &#34;RFB_mobile&#34;;

    self.system_dict[&#34;params&#34;][&#34;trained_model&#34;] = weights;        

    if(use_gpu):
        self.system_dict[&#34;params&#34;][&#34;cuda&#34;] = True;
        self.system_dict[&#34;params&#34;][&#34;cpu&#34;] = False;
    else:
        self.system_dict[&#34;params&#34;][&#34;cuda&#34;] = False;
        self.system_dict[&#34;params&#34;][&#34;cpu&#34;] = True;</code></pre>
</details>
</dd>
<dt id="8_pytorch_rfbnet.lib.infer_detector.Infer.Predict"><code class="name flex">
<span>def <span class="ident">Predict</span></span>(<span>self, img_file, thresh=0.7, font_size=1, line_size=5)</span>
</code></dt>
<dd>
<div class="desc"><p>User function: Run inference on image and visualize it</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>img_file</code></strong> :&ensp;<code>str</code></dt>
<dd>Relative path to the image file</dd>
<dt><strong><code>thresh</code></strong> :&ensp;<code>float</code></dt>
<dd>Threshold for predicted scores. Scores for objects detected below this score will not be displayed </dd>
<dt><strong><code>font_size</code></strong> :&ensp;<code>int</code></dt>
<dd>Font size for text of label names on predicted images</dd>
<dt><strong><code>line_size</code></strong> :&ensp;<code>int</code></dt>
<dd>Drawn bounding boxes line widths</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list</code></dt>
<dd>List of bounding box locations of predicted objects.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def Predict(self, img_file, thresh=0.7, font_size=1, line_size=5):
    &#39;&#39;&#39;
    User function: Run inference on image and visualize it

    Args:
        img_file (str): Relative path to the image file
        thresh (float): Threshold for predicted scores. Scores for objects detected below this score will not be displayed 
        font_size (int): Font size for text of label names on predicted images
        line_size (int): Drawn bounding boxes line widths

    Returns:
        list: List of bounding box locations of predicted objects. 
    &#39;&#39;&#39;
    top_k = 200
    img_dim = (300,512)[self.system_dict[&#34;params&#34;][&#34;size&#34;] == 512]
    num_classes = len(self.system_dict[&#34;local&#34;][&#34;classes&#34;])

    rgb_means = ((104, 117, 123),(103.94,116.78,123.68))[self.system_dict[&#34;params&#34;][&#34;version&#34;] == &#39;RFB_mobile&#39;]

    cuda = self.system_dict[&#34;params&#34;][&#34;cuda&#34;];
    transform = BaseTransform(self.system_dict[&#34;local&#34;][&#34;net&#34;].size, rgb_means, (2, 0, 1))
    max_per_image = top_k
    
    num_images = 1
    all_boxes = [];

    _t = {&#39;im_detect&#39;: Timer(), &#39;misc&#39;: Timer()}
    det_file = os.path.join(&#39;detections.pkl&#39;)

    
    img_id = img_file;
    img = cv2.imread(img_id, cv2.IMREAD_COLOR)
    img2 = cv2.imread(img_id, cv2.IMREAD_COLOR)

    scale = torch.Tensor([img.shape[1], img.shape[0],
                 img.shape[1], img.shape[0]])
    with torch.no_grad():
        x = transform(img).unsqueeze(0)
        if cuda:
            x = x.cuda()
            scale = scale.cuda()

    _t[&#39;im_detect&#39;].tic()
    out = self.system_dict[&#34;local&#34;][&#34;net&#34;](x)      # forward pass
    boxes, scores = self.system_dict[&#34;local&#34;][&#34;detector&#34;].forward(out, self.system_dict[&#34;local&#34;][&#34;priors&#34;])
    detect_time = _t[&#39;im_detect&#39;].toc()
    boxes = boxes[0]
    scores=scores[0]

    boxes *= scale
    boxes = boxes.cpu().numpy()
    scores = scores.cpu().numpy()
    # scale each detection back up to the image

    _t[&#39;misc&#39;].tic()

    classes = self.system_dict[&#34;local&#34;][&#34;classes&#34;];

    for j in range(1, num_classes):
        inds = np.where(scores[:, j] &gt; thresh)[0]
        if len(inds) == 0:
            continue
        c_bboxes = boxes[inds]
        c_scores = scores[inds, j]
        c_dets = np.hstack((c_bboxes, c_scores[:, np.newaxis])).astype(
            np.float32, copy=False)

        keep = nms(c_dets, 0.45, force_cpu=self.system_dict[&#34;params&#34;][&#34;cpu&#34;])
        c_dets = c_dets[keep, :]
        c_bboxes=c_dets[:, :4]
        print(len(c_bboxes), j)
        for bbox in c_bboxes:
            cv2.rectangle(img2, (int(bbox[0]), int(bbox[1])), (int(bbox[2]), int(bbox[3])), (0, 0, 255), line_size)
            cv2.putText(img2, classes[j], (int(bbox[0]), int(bbox[1])) , 
                        cv2.FONT_HERSHEY_SIMPLEX, font_size, (0, 0, 255), line_size-2)
            all_boxes.append([int(bbox[0]), int(bbox[1]), int(bbox[2]), int(bbox[3]), classes[j]])
        
    cv2.imwrite(&#34;output.png&#34;, img2)

    return all_boxes;</code></pre>
</details>
</dd>
<dt id="8_pytorch_rfbnet.lib.infer_detector.Infer.Setup"><code class="name flex">
<span>def <span class="ident">Setup</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>User function: Setup all parameters</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>None</code></strong></dt>
<dd>&nbsp;</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>None</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def Setup(self):
    &#39;&#39;&#39;
    User function: Setup all parameters

    Args:
        None

    Returns:
        None
    &#39;&#39;&#39;
    if(self.system_dict[&#34;params&#34;][&#34;size&#34;] == 300):
        self.system_dict[&#34;local&#34;][&#34;cfg&#34;] = COCO_300;
    else:
        self.system_dict[&#34;local&#34;][&#34;cfg&#34;] = COCO_512;


    if self.system_dict[&#34;params&#34;][&#34;version&#34;] == &#39;RFB_vgg&#39;:
        from models.RFB_Net_vgg import build_net
    elif self.system_dict[&#34;params&#34;][&#34;version&#34;] == &#39;RFB_E_vgg&#39;:
        from models.RFB_Net_E_vgg import build_net
    elif self.system_dict[&#34;params&#34;][&#34;version&#34;] == &#39;RFB_mobile&#39;:
        from models.RFB_Net_mobile import build_net
        self.system_dict[&#34;local&#34;][&#34;cfg&#34;] = COCO_mobile_300
    else:
        print(&#39;Unkown version!&#39;)


    self.system_dict[&#34;local&#34;][&#34;priorbox&#34;] = PriorBox(self.system_dict[&#34;local&#34;][&#34;cfg&#34;])
    with torch.no_grad():
        self.system_dict[&#34;local&#34;][&#34;priors&#34;] = self.system_dict[&#34;local&#34;][&#34;priorbox&#34;].forward()
        if self.system_dict[&#34;params&#34;][&#34;cuda&#34;]:
            self.system_dict[&#34;local&#34;][&#34;priors&#34;] = self.system_dict[&#34;local&#34;][&#34;priors&#34;].cuda()


    img_dim = (300,512)[self.system_dict[&#34;params&#34;][&#34;size&#34;] == 512]
    num_classes = len(self.system_dict[&#34;local&#34;][&#34;classes&#34;])
    self.system_dict[&#34;local&#34;][&#34;net&#34;] = build_net(&#39;test&#39;, img_dim, num_classes)
    state_dict = torch.load(self.system_dict[&#34;params&#34;][&#34;trained_model&#34;])


    from collections import OrderedDict
    new_state_dict = OrderedDict()
    for k, v in state_dict.items():
        head = k[:7]
        if head == &#39;module.&#39;:
            name = k[7:] # remove `module.`
        else:
            name = k
        new_state_dict[name] = v
    self.system_dict[&#34;local&#34;][&#34;net&#34;].load_state_dict(new_state_dict)
    self.system_dict[&#34;local&#34;][&#34;net&#34;].eval()
    print(&#39;Finished loading model!&#39;)

    if self.system_dict[&#34;params&#34;][&#34;cuda&#34;]:
        self.system_dict[&#34;local&#34;][&#34;net&#34;] = self.system_dict[&#34;local&#34;][&#34;net&#34;].cuda()
        cudnn.benchmark = True
    else:
        self.system_dict[&#34;local&#34;][&#34;net&#34;] = self.system_dict[&#34;local&#34;][&#34;net&#34;].cpu()

    
    self.system_dict[&#34;local&#34;][&#34;detector&#34;] = Detect(num_classes, 0, self.system_dict[&#34;local&#34;][&#34;cfg&#34;])</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="8_pytorch_rfbnet.lib" href="index.html">8_pytorch_rfbnet.lib</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="8_pytorch_rfbnet.lib.infer_detector.Infer" href="#8_pytorch_rfbnet.lib.infer_detector.Infer">Infer</a></code></h4>
<ul class="">
<li><code><a title="8_pytorch_rfbnet.lib.infer_detector.Infer.Image_Params" href="#8_pytorch_rfbnet.lib.infer_detector.Infer.Image_Params">Image_Params</a></code></li>
<li><code><a title="8_pytorch_rfbnet.lib.infer_detector.Infer.Model" href="#8_pytorch_rfbnet.lib.infer_detector.Infer.Model">Model</a></code></li>
<li><code><a title="8_pytorch_rfbnet.lib.infer_detector.Infer.Predict" href="#8_pytorch_rfbnet.lib.infer_detector.Infer.Predict">Predict</a></code></li>
<li><code><a title="8_pytorch_rfbnet.lib.infer_detector.Infer.Setup" href="#8_pytorch_rfbnet.lib.infer_detector.Infer.Setup">Setup</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.1</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>